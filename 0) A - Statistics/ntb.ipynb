{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics toolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy for datascience\n",
    "\n",
    "# Surprise\n",
    "If we want to define how much we will be surprised if some events based on probability occurs how should we dou that? The first logical step is to define it as an inverse of probability of a given event.\n",
    "\n",
    "$$ S = \\frac{1}{P(X)}, $$\n",
    "\n",
    "where $P(X)$ is the probability of the event $X$. But there is a problem with this definition. If there will be a probability $P(X) = 1$ we should't be surprised that this event will occure. But due to given definition the surprise $S = 1$. We can improve the definition by using logarithm.\n",
    "\n",
    "$$ S = \\log(\\frac{1}{P(X)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssipikal\\AppData\\Local\\Temp\\ipykernel_5180\\3297161144.py:5: RuntimeWarning: divide by zero encountered in divide\n",
      "  y = np.log(1/x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(0, 1, num=100)\n",
    "y = np.log(1/x)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "Entropy is expected value of a surprise. Imagine that we have a coin for which probability of getting head is $P(H) = 0.9$ and probability of getting tail is $P(T) = 0.1$. Let's find the coressponding surprise values using previous mentioned formula.\n",
    "\n",
    "$$ S(H) = \\log(\\frac{1}{P(H)}) = 0.15 \\qquad \\wedge \\qquad S(T) = \\log(\\frac{1}{P(T)}) = 3.32 $$\n",
    "\n",
    "If we want to know the mean surprise that we'll have after few coin flips we have to just multiply each surprise by it's probability and sum up.\n",
    "\n",
    "$$ E = P(H)*S(H) + P(T)*S(T) $$\n",
    "\n",
    "E is the Entropy. Now let's find the general form for n possible results.\n",
    "\n",
    "$$ E = P(H)*S(H) + P(T)*S(T) + \\dots $$\n",
    "$$ E = \\sum P(X)log(\\frac{1}{P(X)}) = \\sum P(X)(log(1) - log(P(X))) = \\sum -P(X)log(P(X)) $$  \n",
    "$$ E = \\sum -P(X)log(P(X)) $$  \n",
    "\n",
    "And that is the general formula for Entropy $E$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
