{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Instead of using linear function to fit the dataset, in this case we will use Sigmoid function to fit the data. Don't be confused that this algorithm is not used to proceed regression but classification.\n",
    "\n",
    "$$ y = \\frac{1}{1 + e^{-x}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, lr, n_iters):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient descent learning\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_predictions)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - Y))\n",
    "            db = (1/n_samples) * np.sum(predictions - Y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_predictions)\n",
    "        class_pred = [0 if y <= 0.5 else 1 for y in y_pred]\n",
    "        return class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssipikal\\AppData\\Local\\Temp\\ipykernel_21672\\68238617.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, Y = bc.data, bc.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = LogisticRegression(lr=0.01, n_iters=1000)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred == y_test)/len(y_test)\n",
    "\n",
    "print(accuracy(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
